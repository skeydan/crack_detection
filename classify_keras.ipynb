{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        #rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        #zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='wrap'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = load_img('data/test/crack/img_equalized_5526_856.png', grayscale=True)  # this is a PIL image\n",
    "#img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "#x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "#x = np.expand_dims(x, axis=0)\n",
    "#x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "#i = 0\n",
    "#for batch in datagen.flow(x, batch_size=1, \n",
    "#                          save_to_dir='preview', save_prefix='img15', save_format='png'):\n",
    "#    i += 1\n",
    "#    if i > 10:\n",
    "#        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(100, 100, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 98, 98, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 98, 98, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 47, 47, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 21, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 60,961\n",
      "Trainable params: 60,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        #zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='wrap'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7897 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(100, 100),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        color_mode = 'grayscale',\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4557 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# this is a similar generator, for validation data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'data/test',\n",
    "        target_size=(100, 100),\n",
    "        batch_size=batch_size,\n",
    "        color_mode = 'grayscale',\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "125/125 [==============================] - 27s - loss: 0.5778 - acc: 0.7170 - val_loss: 0.7182 - val_acc: 0.6138\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - 27s - loss: 0.5189 - acc: 0.7745 - val_loss: 1.6049 - val_acc: 0.3962\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - 32s - loss: 0.4540 - acc: 0.8150 - val_loss: 2.9061 - val_acc: 0.3688\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - 33s - loss: 0.4282 - acc: 0.8208 - val_loss: 5.2789 - val_acc: 0.2587\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - 35s - loss: 0.3744 - acc: 0.8460 - val_loss: 4.5513 - val_acc: 0.2961\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - 33s - loss: 0.3761 - acc: 0.8460 - val_loss: 4.9053 - val_acc: 0.3187\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - 32s - loss: 0.3555 - acc: 0.8530 - val_loss: 5.8816 - val_acc: 0.2863\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - 32s - loss: 0.3477 - acc: 0.8612 - val_loss: 4.7731 - val_acc: 0.3262\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - 33s - loss: 0.3154 - acc: 0.8790 - val_loss: 5.0976 - val_acc: 0.3250\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - 33s - loss: 0.2839 - acc: 0.8910 - val_loss: 6.2177 - val_acc: 0.2811\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - 32s - loss: 0.2981 - acc: 0.8840 - val_loss: 6.3151 - val_acc: 0.3525\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - 32s - loss: 0.3195 - acc: 0.8791 - val_loss: 6.3129 - val_acc: 0.3212\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - 32s - loss: 0.2821 - acc: 0.8940 - val_loss: 5.8603 - val_acc: 0.3513\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - 33s - loss: 0.2741 - acc: 0.8995 - val_loss: 5.7900 - val_acc: 0.3450\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - 32s - loss: 0.2542 - acc: 0.9045 - val_loss: 7.8453 - val_acc: 0.3124\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - 31s - loss: 0.2829 - acc: 0.8925 - val_loss: 7.1584 - val_acc: 0.3325\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - 32s - loss: 0.2645 - acc: 0.9070 - val_loss: 6.9008 - val_acc: 0.3475\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - 32s - loss: 0.2549 - acc: 0.9025 - val_loss: 7.3528 - val_acc: 0.3162\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - 32s - loss: 0.2587 - acc: 0.9085 - val_loss: 6.9471 - val_acc: 0.3088\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - 32s - loss: 0.2292 - acc: 0.9090 - val_loss: 7.1731 - val_acc: 0.3287\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - 32s - loss: 0.2515 - acc: 0.9165 - val_loss: 6.3454 - val_acc: 0.3350\n",
      "Epoch 22/200\n",
      "125/125 [==============================] - 32s - loss: 0.2246 - acc: 0.9225 - val_loss: 7.2515 - val_acc: 0.3700\n",
      "Epoch 23/200\n",
      "125/125 [==============================] - 34s - loss: 0.2403 - acc: 0.9075 - val_loss: 7.2419 - val_acc: 0.3738\n",
      "Epoch 24/200\n",
      "125/125 [==============================] - 35s - loss: 0.2151 - acc: 0.9175 - val_loss: 6.8922 - val_acc: 0.3965\n",
      "Epoch 25/200\n",
      "125/125 [==============================] - 32s - loss: 0.2443 - acc: 0.9085 - val_loss: 8.8669 - val_acc: 0.3075\n",
      "Epoch 26/200\n",
      "125/125 [==============================] - 32s - loss: 0.2232 - acc: 0.9185 - val_loss: 6.8259 - val_acc: 0.4213\n",
      "Epoch 27/200\n",
      "125/125 [==============================] - 34s - loss: 0.2130 - acc: 0.9250 - val_loss: 7.7397 - val_acc: 0.3725\n",
      "Epoch 28/200\n",
      "125/125 [==============================] - 32s - loss: 0.2779 - acc: 0.8971 - val_loss: 7.1778 - val_acc: 0.3725\n",
      "Epoch 29/200\n",
      "125/125 [==============================] - 32s - loss: 0.2202 - acc: 0.9230 - val_loss: 7.5135 - val_acc: 0.3814\n",
      "Epoch 30/200\n",
      "125/125 [==============================] - 32s - loss: 0.2191 - acc: 0.9120 - val_loss: 7.6913 - val_acc: 0.3738\n",
      "Epoch 31/200\n",
      "125/125 [==============================] - 32s - loss: 0.2171 - acc: 0.9255 - val_loss: 5.7736 - val_acc: 0.4412\n",
      "Epoch 32/200\n",
      "125/125 [==============================] - 32s - loss: 0.2169 - acc: 0.9256 - val_loss: 6.1810 - val_acc: 0.3675\n",
      "Epoch 33/200\n",
      "125/125 [==============================] - 32s - loss: 0.2269 - acc: 0.9150 - val_loss: 6.4144 - val_acc: 0.3862\n",
      "Epoch 34/200\n",
      "125/125 [==============================] - 34s - loss: 0.2207 - acc: 0.9180 - val_loss: 5.9477 - val_acc: 0.4316\n",
      "Epoch 35/200\n",
      "125/125 [==============================] - 36s - loss: 0.2148 - acc: 0.9210 - val_loss: 7.1101 - val_acc: 0.4037\n",
      "Epoch 36/200\n",
      "125/125 [==============================] - 34s - loss: 0.1980 - acc: 0.9246 - val_loss: 7.6012 - val_acc: 0.3713\n",
      "Epoch 37/200\n",
      "125/125 [==============================] - 32s - loss: 0.2176 - acc: 0.9230 - val_loss: 6.9924 - val_acc: 0.4150\n",
      "Epoch 38/200\n",
      "125/125 [==============================] - 32s - loss: 0.2102 - acc: 0.9270 - val_loss: 7.6389 - val_acc: 0.3650\n",
      "Epoch 39/200\n",
      "125/125 [==============================] - 32s - loss: 0.2031 - acc: 0.9255 - val_loss: 6.9060 - val_acc: 0.3663\n",
      "Epoch 40/200\n",
      "125/125 [==============================] - 32s - loss: 0.2209 - acc: 0.9236 - val_loss: 7.9239 - val_acc: 0.2825\n",
      "Epoch 41/200\n",
      "125/125 [==============================] - 32s - loss: 0.1846 - acc: 0.9265 - val_loss: 7.6549 - val_acc: 0.4113\n",
      "Epoch 42/200\n",
      "125/125 [==============================] - 33s - loss: 0.2074 - acc: 0.9300 - val_loss: 6.8255 - val_acc: 0.4075\n",
      "Epoch 43/200\n",
      "125/125 [==============================] - 33s - loss: 0.1994 - acc: 0.9275 - val_loss: 7.4798 - val_acc: 0.3864\n",
      "Epoch 44/200\n",
      "125/125 [==============================] - 31s - loss: 0.1975 - acc: 0.9356 - val_loss: 7.5277 - val_acc: 0.3812\n",
      "Epoch 45/200\n",
      "125/125 [==============================] - 31s - loss: 0.1977 - acc: 0.9280 - val_loss: 7.5925 - val_acc: 0.3625\n",
      "Epoch 46/200\n",
      "125/125 [==============================] - 32s - loss: 0.1979 - acc: 0.9325 - val_loss: 6.7760 - val_acc: 0.4138\n",
      "Epoch 47/200\n",
      "125/125 [==============================] - 32s - loss: 0.1982 - acc: 0.9340 - val_loss: 7.4114 - val_acc: 0.3787\n",
      "Epoch 48/200\n",
      "125/125 [==============================] - 33s - loss: 0.2088 - acc: 0.9272 - val_loss: 6.4999 - val_acc: 0.3425\n",
      "Epoch 49/200\n",
      "125/125 [==============================] - 32s - loss: 0.1838 - acc: 0.9390 - val_loss: 8.3484 - val_acc: 0.3287\n",
      "Epoch 50/200\n",
      "125/125 [==============================] - 32s - loss: 0.2106 - acc: 0.9275 - val_loss: 6.1241 - val_acc: 0.3900\n",
      "Epoch 51/200\n",
      "125/125 [==============================] - 31s - loss: 0.1805 - acc: 0.9365 - val_loss: 8.3873 - val_acc: 0.3900\n",
      "Epoch 52/200\n",
      "125/125 [==============================] - 31s - loss: 0.2138 - acc: 0.9325 - val_loss: 8.0521 - val_acc: 0.3975\n",
      "Epoch 53/200\n",
      "125/125 [==============================] - 31s - loss: 0.1944 - acc: 0.9395 - val_loss: 7.4193 - val_acc: 0.3990\n",
      "Epoch 54/200\n",
      "125/125 [==============================] - 31s - loss: 0.1987 - acc: 0.9275 - val_loss: 7.4620 - val_acc: 0.3975\n",
      "Epoch 55/200\n",
      "125/125 [==============================] - 31s - loss: 0.1940 - acc: 0.9390 - val_loss: 7.2477 - val_acc: 0.4238\n",
      "Epoch 56/200\n",
      "125/125 [==============================] - 31s - loss: 0.2029 - acc: 0.9275 - val_loss: 7.7901 - val_acc: 0.4150\n",
      "Epoch 57/200\n",
      "125/125 [==============================] - 31s - loss: 0.1919 - acc: 0.9335 - val_loss: 6.1012 - val_acc: 0.4525\n",
      "Epoch 58/200\n",
      "125/125 [==============================] - 31s - loss: 0.2160 - acc: 0.9220 - val_loss: 7.5736 - val_acc: 0.3713\n",
      "Epoch 59/200\n",
      "125/125 [==============================] - 31s - loss: 0.2014 - acc: 0.9295 - val_loss: 6.7291 - val_acc: 0.4150\n",
      "Epoch 60/200\n",
      "125/125 [==============================] - 31s - loss: 0.2162 - acc: 0.9245 - val_loss: 8.1508 - val_acc: 0.2512\n",
      "Epoch 61/200\n",
      "125/125 [==============================] - 31s - loss: 0.1939 - acc: 0.9335 - val_loss: 7.3365 - val_acc: 0.4425\n",
      "Epoch 62/200\n",
      "125/125 [==============================] - 31s - loss: 0.1875 - acc: 0.9310 - val_loss: 7.4814 - val_acc: 0.4329\n",
      "Epoch 63/200\n",
      "125/125 [==============================] - 31s - loss: 0.1992 - acc: 0.9325 - val_loss: 7.9168 - val_acc: 0.3700\n",
      "Epoch 64/200\n",
      "125/125 [==============================] - 31s - loss: 0.1977 - acc: 0.9385 - val_loss: 7.5315 - val_acc: 0.3600\n",
      "Epoch 65/200\n",
      "125/125 [==============================] - 31s - loss: 0.2450 - acc: 0.9255 - val_loss: 7.2432 - val_acc: 0.4225\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 31s - loss: 0.2047 - acc: 0.9280 - val_loss: 8.9672 - val_acc: 0.2737\n",
      "Epoch 67/200\n",
      "125/125 [==============================] - 31s - loss: 0.2011 - acc: 0.9295 - val_loss: 8.8442 - val_acc: 0.3413\n",
      "Epoch 68/200\n",
      "125/125 [==============================] - 31s - loss: 0.1909 - acc: 0.9306 - val_loss: 8.3117 - val_acc: 0.3675\n",
      "Epoch 69/200\n",
      "125/125 [==============================] - 31s - loss: 0.2164 - acc: 0.9260 - val_loss: 8.2638 - val_acc: 0.3600\n",
      "Epoch 70/200\n",
      "125/125 [==============================] - 31s - loss: 0.2014 - acc: 0.9315 - val_loss: 7.7021 - val_acc: 0.3925\n",
      "Epoch 71/200\n",
      "125/125 [==============================] - 31s - loss: 0.2249 - acc: 0.9235 - val_loss: 7.8880 - val_acc: 0.3800\n",
      "Epoch 72/200\n",
      "125/125 [==============================] - 32s - loss: 0.1805 - acc: 0.9376 - val_loss: 7.9284 - val_acc: 0.3814\n",
      "Epoch 73/200\n",
      "125/125 [==============================] - 31s - loss: 0.1993 - acc: 0.9360 - val_loss: 8.4119 - val_acc: 0.3750\n",
      "Epoch 74/200\n",
      "125/125 [==============================] - 31s - loss: 0.2140 - acc: 0.9290 - val_loss: 7.7647 - val_acc: 0.4000\n",
      "Epoch 75/200\n",
      "125/125 [==============================] - 31s - loss: 0.2038 - acc: 0.9325 - val_loss: 7.9090 - val_acc: 0.4437\n",
      "Epoch 76/200\n",
      "125/125 [==============================] - 31s - loss: 0.2079 - acc: 0.9360 - val_loss: 7.6092 - val_acc: 0.4150\n",
      "Epoch 77/200\n",
      "125/125 [==============================] - 31s - loss: 0.2259 - acc: 0.9265 - val_loss: 8.1128 - val_acc: 0.3500\n",
      "Epoch 78/200\n",
      "125/125 [==============================] - 31s - loss: 0.2386 - acc: 0.9210 - val_loss: 7.4137 - val_acc: 0.4213\n",
      "Epoch 79/200\n",
      "125/125 [==============================] - 31s - loss: 0.2264 - acc: 0.9280 - val_loss: 7.7747 - val_acc: 0.4025\n",
      "Epoch 80/200\n",
      "125/125 [==============================] - 31s - loss: 0.2243 - acc: 0.9285 - val_loss: 7.8907 - val_acc: 0.3613\n",
      "Epoch 81/200\n",
      "125/125 [==============================] - 31s - loss: 0.1929 - acc: 0.9315 - val_loss: 7.7657 - val_acc: 0.4241\n",
      "Epoch 82/200\n",
      "125/125 [==============================] - 31s - loss: 0.2238 - acc: 0.9220 - val_loss: 6.8726 - val_acc: 0.4462\n",
      "Epoch 83/200\n",
      "125/125 [==============================] - 31s - loss: 0.1901 - acc: 0.9380 - val_loss: 8.5255 - val_acc: 0.2512\n",
      "Epoch 84/200\n",
      "125/125 [==============================] - 31s - loss: 0.2040 - acc: 0.9335 - val_loss: 8.2546 - val_acc: 0.3987\n",
      "Epoch 85/200\n",
      "125/125 [==============================] - 31s - loss: 0.2387 - acc: 0.9185 - val_loss: 7.5565 - val_acc: 0.4100\n",
      "Epoch 86/200\n",
      "125/125 [==============================] - 31s - loss: 0.2256 - acc: 0.9290 - val_loss: 7.4237 - val_acc: 0.3940\n",
      "Epoch 87/200\n",
      "125/125 [==============================] - 31s - loss: 0.2371 - acc: 0.9215 - val_loss: 8.6032 - val_acc: 0.3387\n",
      "Epoch 88/200\n",
      "125/125 [==============================] - 31s - loss: 0.2232 - acc: 0.9310 - val_loss: 7.0272 - val_acc: 0.4163\n",
      "Epoch 89/200\n",
      "125/125 [==============================] - 31s - loss: 0.1998 - acc: 0.9360 - val_loss: 7.4924 - val_acc: 0.4012\n",
      "Epoch 90/200\n",
      "125/125 [==============================] - 31s - loss: 0.2360 - acc: 0.9200 - val_loss: 7.4665 - val_acc: 0.4163\n",
      "Epoch 91/200\n",
      "125/125 [==============================] - 31s - loss: 0.2025 - acc: 0.9315 - val_loss: 7.8923 - val_acc: 0.3400\n",
      "Epoch 92/200\n",
      "125/125 [==============================] - 31s - loss: 0.2601 - acc: 0.9110 - val_loss: 7.5074 - val_acc: 0.4387\n",
      "Epoch 93/200\n",
      "125/125 [==============================] - 31s - loss: 0.2214 - acc: 0.9260 - val_loss: 7.1724 - val_acc: 0.4250\n",
      "Epoch 94/200\n",
      "125/125 [==============================] - 31s - loss: 0.2293 - acc: 0.9280 - val_loss: 7.8328 - val_acc: 0.3800\n",
      "Epoch 95/200\n",
      "125/125 [==============================] - 32s - loss: 0.2567 - acc: 0.9266 - val_loss: 8.3047 - val_acc: 0.3488\n",
      "Epoch 96/200\n",
      "125/125 [==============================] - 35s - loss: 0.2256 - acc: 0.9280 - val_loss: 6.9541 - val_acc: 0.4688\n",
      "Epoch 97/200\n",
      "125/125 [==============================] - 31s - loss: 0.2218 - acc: 0.9295 - val_loss: 8.0442 - val_acc: 0.3488\n",
      "Epoch 98/200\n",
      "125/125 [==============================] - 34s - loss: 0.2803 - acc: 0.9195 - val_loss: 8.6001 - val_acc: 0.3787\n",
      "Epoch 99/200\n",
      "125/125 [==============================] - 33s - loss: 0.2234 - acc: 0.9266 - val_loss: 8.1721 - val_acc: 0.3575\n",
      "Epoch 100/200\n",
      "125/125 [==============================] - 32s - loss: 0.2248 - acc: 0.9285 - val_loss: 8.0990 - val_acc: 0.3814\n",
      "Epoch 101/200\n",
      "125/125 [==============================] - 32s - loss: 0.2123 - acc: 0.9315 - val_loss: 8.5969 - val_acc: 0.3663\n",
      "Epoch 102/200\n",
      "125/125 [==============================] - 32s - loss: 0.2184 - acc: 0.9250 - val_loss: 7.8374 - val_acc: 0.4125\n",
      "Epoch 103/200\n",
      "125/125 [==============================] - 32s - loss: 0.2586 - acc: 0.9276 - val_loss: 8.5341 - val_acc: 0.3663\n",
      "Epoch 104/200\n",
      "125/125 [==============================] - 32s - loss: 0.2398 - acc: 0.9120 - val_loss: 8.3709 - val_acc: 0.3850\n",
      "Epoch 105/200\n",
      "125/125 [==============================] - 32s - loss: 0.2773 - acc: 0.9115 - val_loss: 6.5317 - val_acc: 0.4253\n",
      "Epoch 106/200\n",
      "125/125 [==============================] - 32s - loss: 0.2636 - acc: 0.9180 - val_loss: 8.3332 - val_acc: 0.4138\n",
      "Epoch 107/200\n",
      "125/125 [==============================] - 32s - loss: 0.2536 - acc: 0.9257 - val_loss: 8.0451 - val_acc: 0.4075\n",
      "Epoch 108/200\n",
      "125/125 [==============================] - 32s - loss: 0.2161 - acc: 0.9290 - val_loss: 7.8575 - val_acc: 0.4050\n",
      "Epoch 109/200\n",
      "125/125 [==============================] - 31s - loss: 0.2472 - acc: 0.9115 - val_loss: 9.1186 - val_acc: 0.3137\n",
      "Epoch 110/200\n",
      "125/125 [==============================] - 32s - loss: 0.2840 - acc: 0.9125 - val_loss: 8.2597 - val_acc: 0.3802\n",
      "Epoch 111/200\n",
      "125/125 [==============================] - 31s - loss: 0.2512 - acc: 0.9206 - val_loss: 7.3262 - val_acc: 0.4200\n",
      "Epoch 112/200\n",
      "125/125 [==============================] - 32s - loss: 0.2319 - acc: 0.9295 - val_loss: 7.8682 - val_acc: 0.3525\n",
      "Epoch 113/200\n",
      "125/125 [==============================] - 32s - loss: 0.2968 - acc: 0.9110 - val_loss: 7.2293 - val_acc: 0.4150\n",
      "Epoch 114/200\n",
      "125/125 [==============================] - 34s - loss: 0.2503 - acc: 0.9160 - val_loss: 7.1387 - val_acc: 0.4050\n",
      "Epoch 115/200\n",
      "125/125 [==============================] - 36s - loss: 0.2514 - acc: 0.9166 - val_loss: 8.3538 - val_acc: 0.3750\n",
      "Epoch 116/200\n",
      "125/125 [==============================] - 36s - loss: 0.2741 - acc: 0.9135 - val_loss: 8.1580 - val_acc: 0.3850\n",
      "Epoch 117/200\n",
      " 65/125 [==============>...............] - ETA: 14s - loss: 0.3113 - acc: 0.9135"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=200,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=800 // batch_size)\n",
    "model.save_weights('first_try.h5')  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
